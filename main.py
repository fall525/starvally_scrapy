import os
import time
from distributed_distribution_manager import DistributedDistributionManager
from db_manager import DBManager
import settings


db_manager = DBManager(
    host=settings.MONGODB_HOST,
    port=settings.MONGODB_PORT,
    db_name=settings.MONGODB_DB_NAME,
    col_name=settings.MONGODB_COLL_NAME
)

url_manager = DistributedDistributionManager(
    host=settings.REDIS_HOST,
    port=settings.REDIS_PORT,
    db=settings.REDIS_DB
)


# å¯åŠ¨çˆ¬è™«ç¨‹åº
def start_crawler():
    try:
        print("ğŸš€ å¯åŠ¨çˆ¬è™«ç¨‹åº...")
        os.system("python crawler_dis.py")
    except Exception as e:
        print(f"âŒ å¯åŠ¨çˆ¬è™«å¤±è´¥: {e}")


def main():
    print("ğŸš€ å¯åŠ¨åˆ†å¸ƒå¼çˆ¬è™«ç³»ç»Ÿ")
    # push_seed_urls(settings.SEED_URLS)
    start_crawler()

    # ç®€å•ç›‘æ§
    while True:
        time.sleep(10)
        url_count = url_manager.queue_size()
        page_count = db_manager.count_pages()
        print(f"ğŸ“Š å½“å‰å¾…çˆ¬å–URLæ•°é‡: {url_count}, å·²å­˜å‚¨é¡µé¢æ•°é‡: {page_count}")

if __name__ == "__main__":
    main()
