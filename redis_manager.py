import redis
import time
class RedisManager:
    def __init__(self, host="127.0.0.1", port=6379, db=0):
        self.redis_client = redis.StrictRedis(host=host, port=port, db=db, decode_responses=True)

    ### ğŸ“Œ 1ï¸âƒ£ ä»»åŠ¡é˜Ÿåˆ— ###
    def push_url(self, url):
        """å°†æ–° URL æ·»åŠ åˆ°ä»»åŠ¡é˜Ÿåˆ—"""
        if not self.is_visited(url):
            self.redis_client.lpush("url_queue", url)

    def pop_url(self):
        """è·å–ä»»åŠ¡é˜Ÿåˆ—ä¸­çš„ URL"""
        return self.redis_client.rpop("url_queue")

    def queue_size(self):
        """è·å–ä»»åŠ¡é˜Ÿåˆ—å¤§å°"""
        return self.redis_client.llen("url_queue")

    ### ğŸ“Œ 2ï¸âƒ£ å»é‡æœºåˆ¶ ###
    def is_visited(self, url):
        """åˆ¤æ–­ URL æ˜¯å¦å·²ç»çˆ¬å–"""
        return self.redis_client.sismember("visited_urls", url)

    def mark_visited(self, url):
        """è®°å½• URL ä¸ºå·²çˆ¬å–"""
        self.redis_client.sadd("visited_urls", url)

    ### ğŸ“Œ 3ï¸âƒ£ ä»»åŠ¡çŠ¶æ€ç®¡ç† ###
    def set_status(self, url, status):
        """è®¾ç½® URL çš„çˆ¬å–çŠ¶æ€ (crawling, done, failed)"""
        self.redis_client.hset("url_status", url, status)

    def get_status(self, url):
        """è·å– URL å½“å‰çš„çˆ¬å–çŠ¶æ€"""
        return self.redis_client.hget("url_status", url)

    ### ğŸ“Œ 4ï¸âƒ£ å¤±è´¥é‡è¯•æœºåˆ¶ ###
    def push_failed_url(self, url):
        """å°†çˆ¬å–å¤±è´¥çš„ URL å­˜å…¥å¤±è´¥é˜Ÿåˆ—"""
        self.redis_client.lpush("failed_urls", url)

    def get_failed_urls(self):
        """è·å–æ‰€æœ‰çˆ¬å–å¤±è´¥çš„ URL"""
        return self.redis_client.lrange("failed_urls", 0, -1)
    def failed_queue_size(self):
        """è·å–ä»»åŠ¡é˜Ÿåˆ—å¤§å°"""
        return self.redis_client.llen("failed_urls")
    
    ### ğŸ“Œ 5ï¸âƒ£ çˆ¬è™«è¿›ç¨‹çŠ¶æ€ç®¡ç† ###
    def add_active_crawler(self, pid):
        """å°†çˆ¬è™«è¿›ç¨‹ ID æ·»åŠ åˆ°æ´»è·ƒè¿›ç¨‹é›†åˆä¸­"""
        self.redis_client.sadd("active_crawlers", pid)

    def remove_active_crawler(self, pid):
        """ä»æ´»è·ƒè¿›ç¨‹é›†åˆä¸­ç§»é™¤æŒ‡å®šçˆ¬è™«è¿›ç¨‹ ID"""
        self.redis_client.srem("active_crawlers", pid)

    def get_active_crawlers(self):
        """è·å–æ‰€æœ‰æ´»è·ƒçš„çˆ¬è™«è¿›ç¨‹ ID"""
        return self.redis_client.smembers("active_crawlers")

    
    def set_crawler_status(self, pid, status_info):
        """è®¾ç½®æŒ‡å®šçˆ¬è™«è¿›ç¨‹çš„çŠ¶æ€ä¿¡æ¯ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ Redisï¼‰"""
        if isinstance(status_info, dict):
            for key, value in status_info.items():
                self.redis_client.hset(f"crawler:status:{pid}", key, value)
        else:
            print(f"âŒ çŠ¶æ€ä¿¡æ¯æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ› dictï¼Œå¾—åˆ°: {type(status_info)}")


    def get_crawler_status(self, pid):
        """è·å–æŒ‡å®šçˆ¬è™«è¿›ç¨‹çš„çŠ¶æ€ä¿¡æ¯"""
        return self.redis_client.hgetall(f"crawler:status:{pid}")

    def clear_crawler_status(self, pid):
        """æ¸…é™¤æŒ‡å®šçˆ¬è™«è¿›ç¨‹çš„çŠ¶æ€ä¿¡æ¯"""
        self.redis_client.delete(f"crawler:status:{pid}")

    def send_heartbeat(self, pid, expire_time=30):
        """å‘é€çˆ¬è™«è¿›ç¨‹çš„å¿ƒè·³ä¿¡å·åˆ° Redis"""
        self.redis_client.set(f"crawler:heartbeat:{pid}", time.time(), ex=expire_time)
